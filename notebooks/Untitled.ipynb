{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba_test import dot, slow_dot, np_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = np.random.rand(10000).astype(np.float32)\n",
    "bar = np.random.rand(10000).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2484.2819370024185"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot(foo, bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "980 µs ± 10.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for _ in range(100):\n",
    "    dot(foo, bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397 ms ± 11 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for _ in range(100):\n",
    "    slow_dot(foo, bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 µs ± 664 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for _ in range(100):\n",
    "    np_dot(foo, bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2484.2819370024185"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_dot(foo,bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2484.2822"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_dot(foo,bar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_beta_vector(T: int,\n",
    "                    α: float,\n",
    "                    β: float) -> np.ndarray:\n",
    "    discount = np.zeros((1, T))\n",
    "\n",
    "    current_discount = 1\n",
    "    for t in range(T):\n",
    "        discount[0, t] = current_discount\n",
    "        current_discount *= (α + t) / (α + β + t)\n",
    "\n",
    "    return discount\n",
    "\n",
    "@njit\n",
    "def beta_gae(rewards: np.ndarray,  # [T, N]\n",
    "             values: np.ndarray,  # [T, N]\n",
    "             last_values: np.ndarray,  # [1, N]\n",
    "             dones: np.ndarray,  # [T, N], actually next_dones (whether previous step was terminal)\n",
    "             final_dones: np.ndarray,  # [1, ]\n",
    "             α: float = 99.,\n",
    "             β: float = 1.,\n",
    "             λ: float = 0.95):\n",
    "    T = rewards.shape[0]\n",
    "    N = rewards.shape[1]  # Number of envs\n",
    "\n",
    "    # TODO: Handle multiple envs separately to work with Hopper AAAGH\n",
    "\n",
    "    advantages = np.zeros((T, N), dtype=np.float32)\n",
    "\n",
    "    final_dones = final_dones.reshape((1, N))\n",
    "    last_values = last_values.reshape((1, N))\n",
    "    next_non_terminal = 1 - np.concatenate((dones, final_dones))[1:]\n",
    "    next_values = np.concatenate((values, last_values))[1:]\n",
    "\n",
    "    # Process dones\n",
    "    # !!! Assume all environments have episode ends simultaneously !!!\n",
    "    steps_until_eoe = np.zeros((T,), dtype=np.int32)\n",
    "    is_final = np.zeros((T,), dtype=np.int32)  # Might be starting too early OOBE\n",
    "    counter = 0\n",
    "    final = 1\n",
    "    done = False\n",
    "    for i, d in list(enumerate(dones[:, 0]))[::-1]:\n",
    "        if done:\n",
    "            counter = 0\n",
    "            done = False\n",
    "            final = 0\n",
    "        steps_until_eoe[i] = counter\n",
    "        is_final[i] = final\n",
    "        counter += 1\n",
    "        done = d\n",
    "\n",
    "    Γ = get_beta_vector(T + 1, α, β)\n",
    "    lambdas = np.array([[λ ** l for l in range(T)]])\n",
    "\n",
    "    #     γ = α / (α + β)\n",
    "    #     Γ = np.array([[γ**l for l in range(T+1)]])\n",
    "\n",
    "    factor = None\n",
    "\n",
    "    for i in range(T):\n",
    "        steps_left = steps_until_eoe[i]\n",
    "\n",
    "        old_value = -values[i]\n",
    "        future_rewards = (lambdas[:, :steps_left + 1] * Γ[:, :steps_left + 1]) @ rewards[i:i + steps_left + 1]\n",
    "\n",
    "        if is_final[i]:\n",
    "            steps_left += 1\n",
    "\n",
    "            # Fix to properly handle the very last value of an episode\n",
    "            if factor is None:\n",
    "                factor = np.array([[1 - λ for i in range(steps_left)]]).T\n",
    "                factor[-1] = 1.\n",
    "            else:\n",
    "                factor = factor[1:]\n",
    "\n",
    "            future_values = (lambdas[:, :steps_left] * Γ[:, 1:steps_left + 1]) @ (\n",
    "                        next_values[i:i + steps_left] * next_non_terminal[i:i + steps_left] * factor[-steps_left:])\n",
    "\n",
    "        else:\n",
    "            future_values = (1 - λ) * (lambdas[:, :steps_left] * Γ[:, 1:steps_left + 1]) @ (\n",
    "                        next_values[i:i + steps_left] * next_non_terminal[i:i + steps_left])\n",
    "\n",
    "        advantages[i] = old_value + future_rewards + future_values\n",
    "\n",
    "    returns = advantages + values\n",
    "\n",
    "    return returns, advantages\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10000\n",
    "\n",
    "rewards = np.random.rand(T, 1)\n",
    "values = np.random.rand(T, 1)\n",
    "dones = np.zeros_like(rewards)\n",
    "final_dones = np.array([[1]])\n",
    "last_values = np.array([[0.]])\n",
    "\n",
    "dones = np.zeros((T, 1))\n",
    "for i in range(0,T,T//10):\n",
    "    dones[i, 0] = 1 if i > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.4 ms ± 1.83 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "beta_ret, beta_adv = beta_gae(rewards, values, last_values, dones, final_dones, 9., 1., 0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit\n",
    "def get_beta_vector(T: int,\n",
    "                    α: float,\n",
    "                    β: float) -> np.ndarray:\n",
    "    discount = np.zeros((1, T))\n",
    "\n",
    "    current_discount = 1\n",
    "    for t in range(T):\n",
    "        discount[0, t] = current_discount\n",
    "        current_discount *= (α + t) / (α + β + t)\n",
    "\n",
    "    return discount\n",
    "\n",
    "# @njit\n",
    "def beta_gae(rewards: np.ndarray,  # [T, N]\n",
    "             values: np.ndarray,  # [T, N]\n",
    "             last_values: np.ndarray,  # [1, N]\n",
    "             dones: np.ndarray,  # [T, N], actually next_dones (whether previous step was terminal)\n",
    "             final_dones: np.ndarray,  # [1, ]\n",
    "             α: float = 99.,\n",
    "             β: float = 1.,\n",
    "             λ: float = 0.95):\n",
    "    T = rewards.shape[0]\n",
    "    N = rewards.shape[1]  # Number of envs\n",
    "\n",
    "    # TODO: Handle multiple envs separately to work with Hopper AAAGH\n",
    "\n",
    "    advantages = np.zeros((T, N), dtype=np.float32)\n",
    "\n",
    "    final_dones = final_dones.reshape((1, N))\n",
    "    last_values = last_values.reshape((1, N))\n",
    "    next_non_terminal = 1 - np.concatenate((dones, final_dones))[1:]\n",
    "    next_values = np.concatenate((values, last_values))[1:]\n",
    "\n",
    "    # Process dones\n",
    "    # !!! Assume all environments have episode ends simultaneously !!!\n",
    "    steps_until_eoe = np.zeros((T,), dtype=np.int32)\n",
    "    is_final = np.zeros((T,), dtype=np.int32)  # Might be starting too early OOBE\n",
    "    counter = 0\n",
    "    final = 1\n",
    "    done = False\n",
    "    for i, d in list(enumerate(dones[:, 0]))[::-1]:\n",
    "        if done:\n",
    "            counter = 0\n",
    "            done = False\n",
    "            final = 0\n",
    "        steps_until_eoe[i] = counter\n",
    "        is_final[i] = final\n",
    "        counter += 1\n",
    "        done = d\n",
    "\n",
    "    Γ = get_beta_vector(T + 1, α, β)\n",
    "    lambdas = np.array([[λ ** l for l in range(T)]])\n",
    "\n",
    "    #     γ = α / (α + β)\n",
    "    #     Γ = np.array([[γ**l for l in range(T+1)]])\n",
    "\n",
    "    factor = None\n",
    "\n",
    "    for i in range(T):\n",
    "        steps_left = steps_until_eoe[i]\n",
    "\n",
    "        old_value = -values[i]\n",
    "        future_rewards = (lambdas[:, :steps_left + 1] * Γ[:, :steps_left + 1]) @ rewards[i:i + steps_left + 1]\n",
    "\n",
    "        if is_final[i]:\n",
    "            steps_left += 1\n",
    "\n",
    "            # Fix to properly handle the very last value of an episode\n",
    "            if factor is None:\n",
    "                factor = np.array([[1 - λ for i in range(steps_left)]]).T\n",
    "                factor[-1] = 1.\n",
    "            else:\n",
    "                factor = factor[1:]\n",
    "\n",
    "            future_values = (lambdas[:, :steps_left] * Γ[:, 1:steps_left + 1]) @ (\n",
    "                        next_values[i:i + steps_left] * next_non_terminal[i:i + steps_left] * factor[-steps_left:])\n",
    "\n",
    "        else:\n",
    "            future_values = (1 - λ) * (lambdas[:, :steps_left] * Γ[:, 1:steps_left + 1]) @ (\n",
    "                        next_values[i:i + steps_left] * next_non_terminal[i:i + steps_left])\n",
    "\n",
    "        advantages[i] = old_value + future_rewards + future_values\n",
    "\n",
    "    returns = advantages + values\n",
    "\n",
    "    return returns, advantages\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229 ms ± 9.46 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "beta_ret, beta_adv = beta_gae(rewards, values, last_values, dones, final_dones, 9., 1., 0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (beta)",
   "language": "python",
   "name": "beta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
